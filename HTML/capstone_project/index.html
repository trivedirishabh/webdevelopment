<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Resume</title>
</head>
<body>
<h1 align="center"> RISHABH TRIVEDI
<img src="./assets/images/img.jpeg" height="100" align="right"></h1><br />
<br />
<hr />
<h1>Summary</h1>
    <p>
        Enthusiastic and driven Cloud Solutions Architect with 10+ years of experience in Banking and Finance Domain.
    Possesses strong abilities in architecting & implementing data & analytics solutions both on-premise & cloud. Possess
    strong leadership skills & enthusiastic about innovations in the field of data & analytics.
    </p>
    <hr />
<h1>Education</h1>
    <p>Madan Mohan Malaviya Engineering College (MMMEC), India <br />
        Bachelor’s Degree in Electronics & Communication Engineering - 2013<br />
        Project: Vending Machine Controller <br />
        Percentage: 80.2%
    </p>
    <hr />
<h1>Work Experience</h1>
<h2>Deutsche Börse, Frankfurt - Germany</h2>
<h3>Cloud Solutions Architect - Data & Analytics - Jul 2020 – Present</h3>
<ul>
    <li>Specialized in developing and deploying scalable data and
    Analytics solutions using Microsoft Azure, optimizing
    performance and driving innovation.</li>
    <li>Worked on testing & deploying Analytics solutions on GCP.</li>
    <li>Designed and executed a strategy for migrating Azure
    cloud resources between subscriptions, optimizing resource
    allocation, enhancing cost-efficiency, and ensuring minimal
    disruption to operations.</li>
    <li>Led the successful strategy and migration of a 3-tier
    application from an on-premises environment to Azure
    Cloud using PaaS solutions.</li>
    <li>Executed a proof of concept for deploying Looker on
    Google Cloud with Extensions, meticulously aligning the
    deployment with the organization's security model to
    ensure robust data protection and compliance.</li>
    <li>Leveraged Google Cloud’s native services and Databricks’
    Delta Sharing framework to design and implement a
    modern data mesh architecture, facilitating decentralized
    data management & sharing across the organization.</li>
    <li>Developed and implemented real-time data analytics
    solutions by integrating Apache Kafka with Azure
    Databricks, enabling swift data processing and immediate
    insights for business-critical decisions.</li>
    <li>Streamlined infrastructure deployment and management by
    automating processes with Terraform, Atlantis, and GitHub
    Actions workflows, ensuring efficient, consistent, and
    scalable cloud infrastructure.</li>
    <li>Conducted successful POC for CDC using Kafka Connect
    and SQL Connector, showcasing potential improvements in
    data synchronization and consistency.</li>
</ul>
<h2>Tata Consultancy Service, Gurugram - India</h2>
<h3>Big Data Engineer – Dec 2013 – Jun 2020</h3>
<h4>Client - Deutsche Bank</h4>
<h5>Project - Enterprise Analytics Platform</h5>
<ul>
    <li>Supported and Maintained petabyte scale Data Lake/Hadoop Platform which was used by over 1500 Users.</li>
    <li>Experience with performance tuning of various components in Hadoop Ecosystem such as hdfs, spark, and
    impala.</li>
    <li>Extensive experience with Apache Hadoop ecosystem & its components.</li>
    Designed internal process improvements to automate repetitive tasks, reducing project delivery times to 33%.</li>
    <li>Created multi-site system architecture plans to manage business continuity and ensured 100% availability of
    systems as part of disaster recovery (DR) strategy.</li>
    <li>Collaborated with system architects, design analysts and others to understand business and industry
    requirements.</li>
    <li>Worked on documenting solutions, creating User Guides for best practices.</li>
    Planned and installed upgrades of Cloudera Data Hub(CDH) software to enhance cluster performance</li>
    <li>Successfully executed performance benchmarking tests for distributed storage and processing such as DFSIO,
    TPCH & TPCDS on Hadoop Clusters.</li>
    <li>Reviewed project requests describing user needs to estimate time and cost required to accomplish projects.</li>
    <li>Worked in a fast-paced agile development environment to quickly analyze, develop, and test potential use cases
    for the business.</li>
    <li>Extensive experience working with customers in New York, London, Germany and India in onsite-offshore
    engagements using Waterfall and Agile delivery models.</li>
</ul>
<hr />
<h1>Skills</h1>
<h2>Technical</h2>
<ul>
    <li>Data Collection: Flume, Kafka, Sqoop, Kinesis</li>
    <li>Storage Formats: Avro, Parquet, JSON.</li>
    <li>Data Processing: Mapreduce, Spark</li>
    <li>SQL on Hadoop: Hive, Impala, SparkSQL</li>
    <li>Search & Analytics: Solr</li>
    <li>Data Science: Zeppelin, cdsw, Azure Databricks</li>
    <li>Other: Hue, HCatalog, Zookeeper</li>
    <li>Languages: SQL, HQL, Python & Bash</li>
</ul>
<h2>Operations & Deployment</h2>
<ul>Visual Studio Code, Service Now, Github, Ansible, Terraform, JIRA, CRM7 and Confluence.</ul>
<h2>Language</h2>
<ul>English, Hindi, German</ul>
<hr />
<h1>Certifications</h1>
<h3>Amazon Web Services</h3>
<ul>
    <li>Data & Analytics – Speciality</li>
    <li>Solutions Architect – Professional</li>
    <li>Solutions Architect – Associate</li>
    <li>Cloud Practitioner</li>
</ul>
<h3>Microsoft Azure</h3>
<ul>
    <li>Azure Fundamentals</li>
    <li>Azure Administrator Associate</li>
    <li>Solutions Architect Expert</li>
</ul>
<h3>Google Cloud Platform</h3>
<ul>
    <li>Associate Data Engineer</li>
</ul>
<h3>Databricks</h3>
<ul>
    <li>Data Engineer Associate</li>
    <li>Data Engineer Professional</li>
</ul>
<h3>Others</h3>
<ul>telc GmbH - German Language B1</ul>
<footer>
    <small>
        Copyright rishabh trivedi © 2024. All Rights Reserved
    </small>
</footer>

</body>
</html>